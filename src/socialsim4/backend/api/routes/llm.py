# src/socialsim4/backend/api/routes/llm.py
from __future__ import annotations

from typing import Any, List, Optional
import logging
logger = logging.getLogger(__name__)
from litestar import Router, post
from litestar.connection import Request
from pydantic import BaseModel, Field
from sqlalchemy import select
from sqlalchemy.ext.asyncio import AsyncSession

from ...core.database import get_session
from ...dependencies import extract_bearer_token, resolve_current_user
from ...models.user import ProviderConfig

# ğŸ‘‡ å…³é”®ï¼šè¿™é‡Œéœ€è¦ä¸Šå‡ 3 å±‚åˆ° socialsim4ï¼Œç„¶åå†è¿›å…¥ core
from ....core.llm import create_llm_client
from ....core.llm_config import LLMConfig

class GenerateAgentsRequest(BaseModel):
    count: int = Field(5, ge=1, le=50)
    description: str
    # å‰ç«¯ generateAgentsWithAI é‡Œä¼ çš„ provider_id
    provider_id: Optional[int] = None


class GeneratedAgent(BaseModel):
    id: Optional[str] = None
    name: str
    role: Optional[str] = None
    profile: Optional[str] = None
    provider: Optional[str] = None
    model: Optional[str] = None
    properties: dict[str, Any] = {}
    history: dict[str, Any] = {}
    memory: list[Any] = []
    knowledgeBase: list[Any] = []


class RefineReportRequest(BaseModel):
    prompt: str
    provider_id: Optional[int] = None


async def _select_provider(
    session: AsyncSession,
    user_id: int,
    provider_id: Optional[int],
) -> ProviderConfig:
    # ä¼˜å…ˆç”¨å‰ç«¯ä¼ å…¥çš„ provider_id
    if provider_id is not None:
        result = await session.execute(
            select(ProviderConfig).where(
                ProviderConfig.user_id == user_id,
                ProviderConfig.id == provider_id,
            )
        )
        provider = result.scalars().first()
        if provider is None:
            raise RuntimeError("æŒ‡å®šçš„ LLM æä¾›å•†ä¸å­˜åœ¨æˆ–ä¸å±äºå½“å‰ç”¨æˆ·")
    else:
        # å¦åˆ™æ‰¾ config.active çš„é‚£ä¸ªï¼›éƒ½æ²¡æ ‡ active å°±éšä¾¿æŒ‘ä¸€ä¸ª
        result = await session.execute(
            select(ProviderConfig).where(ProviderConfig.user_id == user_id)
        )
        items = result.scalars().all()
        active = [p for p in items if (p.config or {}).get("active")]
        provider = active[0] if len(active) == 1 else (items[0] if items else None)

    if provider is None:
            raise RuntimeError("LLM provider not configured")

    dialect = (provider.provider or "").lower()
    if dialect not in {"openai", "gemini", "mock"}:
        raise RuntimeError("Invalid LLM provider dialect")
    if dialect != "mock" and not provider.api_key:
        raise RuntimeError("LLM API key required")
    if not provider.model:
        raise RuntimeError("LLM model required")

    return provider
@post("/generate_agents")
async def generate_agents(
    request: Request,
    data: GenerateAgentsRequest,
) -> List[GeneratedAgent]:
    """
    POST /llm/generate_agents

    å‰ç«¯çš„ generateAgentsWithAI() å°±æ˜¯è°ƒçš„è¿™ä¸ªæ¥å£ã€‚
    """
    token = extract_bearer_token(request)

    async with get_session() as session:
        current_user = await resolve_current_user(session, token)

        provider = await _select_provider(
            session, current_user.id, data.provider_id
        )

        cfg = LLMConfig(
            dialect=(provider.provider or "").lower(),
            api_key=provider.api_key or "",
            model=provider.model,
            base_url=provider.base_url,
            temperature=0.7,
            top_p=1.0,
            frequency_penalty=0.0,
            presence_penalty=0.0,
            max_tokens=1024,
        )
        llm = create_llm_client(cfg)

        system_prompt = (
            "You are an agent generator for a social simulation platform. "
            "Generate a list of diverse agents based on the user's scenario description. "
            "IMPORTANT: Return ONLY a valid JSON array, no markdown, no explanation, no code blocks. "
            "Each agent must have: name (string), role (string), profile (string), properties (object)."
        )

        user_prompt = (
            f"Generate exactly {data.count} diverse agents for this scenario:\n\n"
            f"{data.description}\n\n"
            "Requirements:\n"
            "1. Each agent should have different identity, stance, and personality\n"
            "2. Return ONLY a JSON array in this exact format:\n"
            '[\n'
            '  {"name": "Zhang San", "role": "Village Chief", "profile": "60-year-old respected leader...", "properties": {"trust": 70}},\n'
            '  {"name": "Li Si", "role": "Merchant", "profile": "45-year-old shrewd businessman...", "properties": {"trust": 45}}\n'
            ']\n\n'
            "OUTPUT ONLY THE JSON ARRAY, NO OTHER TEXT:"
        )

        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt},
        ]

        raw_text = llm.chat(messages)
   # æ‰“å°åŸå§‹è¾“å‡ºç”¨äºè°ƒè¯•
        logger.debug(f"LLM raw output (first 500 chars): {raw_text[:500]}")
        
        import json
        import re
        
        # æ¸…ç† LLM è¾“å‡ºï¼šå»é™¤ markdown ä»£ç å—æ ‡è®°
        cleaned_text = raw_text.strip()

        # ç§»é™¤markdownä»£ç å—æ ‡è®°
        if cleaned_text.startswith("```"):
            # åŒ¹é… ```json æˆ– ``` å¼€å¤´çš„ä»£ç å—
            match = re.search(r'```(?:json)?\s*\n(.*?)\n```', cleaned_text, re.DOTALL)
            if match:
                cleaned_text = match.group(1).strip()
            else:
                # ç®€å•ç§»é™¤```æ ‡è®°
                cleaned_text = re.sub(r'^```(?:json)?|```$', '', cleaned_text, flags=re.MULTILINE).strip()
        
        # å°è¯•æ‰¾åˆ°ç¬¬ä¸€ä¸ª[æˆ–{
        json_start = min(
            (cleaned_text.find('[') if '[' in cleaned_text else len(cleaned_text)),
            (cleaned_text.find('{') if '{' in cleaned_text else len(cleaned_text))
        )
        if json_start < len(cleaned_text):
            cleaned_text = cleaned_text[json_start:]

        try:
            parsed = json.loads(cleaned_text)
        except Exception as e:
            logger.error(f"JSON parse failed: {e}")
            logger.error(f"Cleaned text (first 300 chars): {cleaned_text[:300]}")
            # LLM æ²¡æŒ‰è¦æ±‚è¿”å› JSON æ—¶çš„å…œåº•ï¼Œå‰ç«¯ä¾ç„¶èƒ½è·‘
            parsed = [
                {
                    "name": f"Agent {i+1}",
                    "role": "è§’è‰²",
                    "profile": f"LLMè¿”å›æ ¼å¼é”™è¯¯ã€‚åŸå§‹è¾“å‡º: {raw_text[:100]}...",
                    "properties": {},
                }
                for i in range(data.count)
            ]

        # å¤„ç†ä¸åŒçš„è¿”å›æ ¼å¼
        if isinstance(parsed, dict) and "agents" in parsed:
            items = parsed["agents"]
        elif isinstance(parsed, list):
            items = parsed
        else:
            # å¦‚æœè§£æå‡ºæ¥ä¸æ˜¯åˆ—è¡¨ä¹Ÿä¸æ˜¯åŒ…å« agents çš„å­—å…¸ï¼Œåˆ›å»ºå ä½è§’è‰²
            items = []

        if not isinstance(items, list):
            items = []

        agents: List[GeneratedAgent] = []
        for i, a in enumerate(items):
            if not isinstance(a, dict):
                continue
            agents.append(
                GeneratedAgent(
                    id=a.get("id") or None,
                    name=a.get("name") or f"Agent {i+1}",
                    role=a.get("role"),
                    profile=a.get("profile"),
                    provider=provider.provider or "backend",
                    model=provider.model or "default",
                    properties=a.get("properties") or {},
                    history=a.get("history") or {},
                    memory=a.get("memory") or [],
                    knowledgeBase=a.get("knowledgeBase") or [],
                )
            )

        # å¦‚æœæ¨¡å‹è¿”å›çš„ä¸è¶³ count ä¸ªï¼Œç®€å•è¡¥é½
        while len(agents) < data.count:
            idx = len(agents)
            agents.append(
                GeneratedAgent(
                    name=f"Agent {idx+1}",
                    role="è§’è‰²",
                    profile=data.description,
                    provider=provider.provider or "backend",
                    model=provider.model or "default",
                )
            )

        return agents


@post("/refine_report")
async def refine_report(request: Request, data: RefineReportRequest) -> dict:
    token = extract_bearer_token(request)

    async with get_session() as session:
        current_user = await resolve_current_user(session, token)
        provider = await _select_provider(session, current_user.id, data.provider_id)
        cfg = LLMConfig(
            dialect=(provider.provider or "").lower(),
            api_key=provider.api_key or "",
            model=provider.model,
            base_url=provider.base_url,
            temperature=0.4,
            top_p=1.0,
            frequency_penalty=0.0,
            presence_penalty=0.0,
            max_tokens=512,
        )
        llm = create_llm_client(cfg)

        messages: list[dict[str, str]] = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€åæŠ¥å‘Šç²¾ç‚¼åŠ©æ‰‹ï¼Œè¯·ä¸¥æ ¼è¿”å› JSONã€‚"},
            {"role": "user", "content": data.prompt},
        ]
        text = llm.chat(messages)
        return {"text": text}
# æš´éœ² /llm å‰ç¼€çš„ Router
router = Router(
    path="/llm",
    route_handlers=[generate_agents, refine_report],
)
