diff --git a/frontend/components/SimulationWizard.tsx b/frontend/components/SimulationWizard.tsx
index f2a1c65..b230d73 100644
--- a/frontend/components/SimulationWizard.tsx
+++ b/frontend/components/SimulationWizard.tsx
@@ -2,7 +2,8 @@
 import React, { useState, useRef, useEffect } from 'react';
 import {
   useSimulationStore,
-  generateAgentsWithAI
+  generateAgentsWithAI,
+  generateAgentsWithDemographics
 } from '../store';
 import {
   X,
@@ -14,7 +15,9 @@ import {
   Clock,
   LayoutTemplate,
   Sparkles,
-  Loader2
+  Loader2,
+  Plus,
+  Minus
 } from 'lucide-react';
 import Papa from 'papaparse';
 import { Agent, LLMConfig, TimeUnit } from '../types';
@@ -28,6 +31,64 @@ const TIME_UNITS: { value: TimeUnit; label: string }[] = [
   { value: 'year', label: 'å¹´' }
 ];
 
+
+
+// =============================================================================
+// Types for Demographic Generation (AgentTorch Integration)
+// =============================================================================
+
+interface Demographic {
+  id: string;
+  name: string;
+  categories: string[];
+}
+
+interface Archetype {
+  id: string;
+  attributes: Record<string, string>;
+  label: string;
+  probability: number;
+}
+
+interface TraitConfig {
+  id: string;
+  name: string;
+  mean: number;
+  std: number;
+}
+
+// Helper to generate unique IDs
+const generateId = () => `${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
+
+// Generate archetypes from demographics (cross-product) - UI helper only
+const generateArchetypes = (demographics: Demographic[]): Archetype[] => {
+  if (demographics.length === 0) return [];
+  
+  let combinations: Record<string, string>[] = demographics[0].categories.map(cat => ({
+    [demographics[0].name]: cat
+  }));
+  
+  for (let i = 1; i < demographics.length; i++) {
+    const demo = demographics[i];
+    const newCombos: Record<string, string>[] = [];
+    for (const combo of combinations) {
+      for (const cat of demo.categories) {
+        newCombos.push({ ...combo, [demo.name]: cat });
+      }
+    }
+    combinations = newCombos;
+  }
+  
+  const equalProb = 1 / combinations.length;
+  return combinations.map((attrs, idx) => ({
+    id: `arch_${idx}`,
+    attributes: attrs,
+    label: Object.entries(attrs).map(([k, v]) => `${k}: ${v}`).join(' | '),
+    probability: equalProb
+  }));
+};
+
+
 export const SimulationWizard: React.FC = () => {
   const isOpen = useSimulationStore((state) => state.isWizardOpen);
   const toggleWizard = useSimulationStore((state) => state.toggleWizard);
@@ -66,6 +127,19 @@ export const SimulationWizard: React.FC = () => {
     'åˆ›å»ºä¸€ä¸ªå¤šå…ƒåŒ–çš„ä¹¡æ‘ç¤¾åŒºï¼ŒåŒ…å«åŠ¡å†œè€…ã€å•†äººå’ŒçŸ¥è¯†åˆ†å­ã€‚'
   );
   const [isGenerating, setIsGenerating] = useState(false);
+  
+  // Demographic-based generation fields (AgentTorch)
+  const [useDemographics, setUseDemographics] = useState(false);
+  const [demographics, setDemographics] = useState<Demographic[]>([
+    { id: generateId(), name: 'Age', categories: ['18-30', '31-50', '51+'] },
+    { id: generateId(), name: 'Location', categories: ['Urban', 'Suburban', 'Rural'] }
+  ]);
+  const [archetypes, setArchetypes] = useState<Archetype[]>([]);
+  const [traits, setTraits] = useState<TraitConfig[]>([
+    { id: generateId(), name: 'Trust', mean: 50, std: 15 },
+    { id: generateId(), name: 'Empathy', mean: 50, std: 15 },
+    { id: generateId(), name: 'Assertiveness', mean: 50, std: 15 }
+  ]);
 
   const fileInputRef = useRef<HTMLInputElement>(null);
 
@@ -95,6 +169,14 @@ export const SimulationWizard: React.FC = () => {
     setGenCount(counts[selectedTemplateId] ?? 5);
   }, [selectedTemplateId]);
 
+  // Update archetypes when demographics change (AgentTorch)
+  useEffect(() => {
+    if (useDemographics) {
+      setArchetypes(generateArchetypes(demographics));
+    }
+  }, [demographics, useDemographics]);
+
+
   const selectedTemplate =
     savedTemplates.find((t) => t.id === selectedTemplateId) ||
     savedTemplates[0];
@@ -155,6 +237,20 @@ export const SimulationWizard: React.FC = () => {
     setGenDesc(
       'åˆ›å»ºä¸€ä¸ªå¤šå…ƒåŒ–çš„ä¹¡æ‘ç¤¾åŒºï¼ŒåŒ…å«åŠ¡å†œè€…ã€å•†äººå’ŒçŸ¥è¯†åˆ†å­ã€‚'
     );
+
+    setUseDemographics(false);
+    setDemographics([
+      { id: generateId(), name: 'Age', categories: ['18-30', '31-50', '51+'] },
+      { id: generateId(), name: 'Location', categories: ['Urban', 'Suburban', 'Rural'] }
+    ]);
+    setArchetypes([]);
+    setTraits([
+      { id: generateId(), name: 'Trust', mean: 50, std: 15 },
+      { id: generateId(), name: 'Empathy', mean: 50, std: 15 },
+      { id: generateId(), name: 'Assertiveness', mean: 50, std: 15 }
+    ]);
+    
+    toggleWizard(false);
   };
 
   const handleDeleteTemplate = (e: React.MouseEvent, id: string) => {
@@ -212,11 +308,43 @@ export const SimulationWizard: React.FC = () => {
     setIsGenerating(true);
     setImportError(null);
     try {
-      const agents = await generateAgentsWithAI(
-        genCount,
-        genDesc,
-        selectedProviderId ?? undefined
-      );
+      let agents: Agent[];
+      
+      if (useDemographics) {
+        // Demographic-based generation
+        const demographicsData = demographics.map(d => ({
+          name: d.name,
+          categories: d.categories
+        }));
+        
+        const traitsData = traits.map(t => ({
+          name: t.name,
+          min: t.mean,
+          max: t.std
+        }));
+        
+        const archetypeProbabilities: Record<string, number> = {};
+        archetypes.forEach(a => {
+          archetypeProbabilities[a.id] = a.probability;
+        });
+        
+        agents = await generateAgentsWithDemographics(
+          genCount,
+          demographicsData,
+          archetypeProbabilities,
+          traitsData,
+          'en',
+          selectedProviderId ?? undefined
+        );
+      } else {
+        // Simple description-based generation
+        agents = await generateAgentsWithAI(
+          genCount,
+          genDesc,
+          selectedProviderId ?? undefined
+        );
+      }
+      
       agents.forEach((a) => {
         a.llmConfig = defaultLlmConfig;
       });
@@ -230,20 +358,98 @@ export const SimulationWizard: React.FC = () => {
     }
   };
 
-  // ç‚¹å‡»â€œä¸‹ä¸€æ­¥â€æ—¶çš„å¤„ç†é€»è¾‘ï¼šå¦‚æœæ²¡æœ‰ä»»ä½•å¯ç”¨æ¨¡å‹ï¼Œæé†’ä¸€ä¸‹
+  // ç‚¹å‡»"ä¸‹ä¸€æ­¥"æ—¶çš„å¤„ç†é€»è¾‘ï¼šå¦‚æœæ²¡æœ‰ä»»ä½•å¯ç”¨æ¨¡å‹ï¼Œæé†’ä¸€ä¸‹
   const handleNext = () => {
     if (llmProviders.length === 0 || !selectedProviderId) {
-      window.alert('æ²¡æœ‰å¯ç”¨æ¨¡å‹ï¼Œè¯·å…ˆåœ¨â€œè®¾ç½® â†’ LLM æä¾›å•†â€ä¸­æ·»åŠ ã€‚');
+      window.alert('æ²¡æœ‰å¯ç”¨æ¨¡å‹ï¼Œè¯·å…ˆåœ¨"è®¾ç½® â†’ LLM æä¾›å•†"ä¸­æ·»åŠ ã€‚');
       addNotification(
         'error',
-        'æ²¡æœ‰å¯ç”¨æ¨¡å‹ï¼Œè¯·å…ˆåœ¨â€œè®¾ç½® â†’ LLM æä¾›å•†â€ä¸­æ·»åŠ ã€‚'
+        'æ²¡æœ‰å¯ç”¨æ¨¡å‹ï¼Œè¯·å…ˆåœ¨"è®¾ç½® â†’ LLM æä¾›å•†"ä¸­æ·»åŠ ã€‚'
       );
-      // è¿™é‡Œé€‰æ‹©â€œæç¤ºä½†ä»ç„¶å…è®¸ç»§ç»­ä¸‹ä¸€æ­¥â€ï¼›å¦‚æœä½ æƒ³é˜»æ­¢ç»§ç»­ï¼Œå¯ä»¥ç›´æ¥ return;
+      // è¿™é‡Œé€‰æ‹©"æç¤ºä½†ä»ç„¶å…è®¸ç»§ç»­ä¸‹ä¸€æ­¥"ï¼›å¦‚æœä½ æƒ³é˜»æ­¢ç»§ç»­ï¼Œå¯ä»¥ç›´æ¥ return;
       // return;
     }
     setStep((s) => s + 1);
   };
 
+  
+  // ========================================================================== 
+  // Demographic management handlers (AgentTorch)
+  // ==========================================================================
+  const handleAddDemographic = () => {
+    setDemographics([
+      ...demographics,
+      { id: generateId(), name: `Dimension ${demographics.length + 1}`, categories: ['A', 'B', 'C'] }
+    ]);
+  };
+
+  const handleRemoveDemographic = (id: string) => {
+    if (demographics.length > 1) {
+      setDemographics(demographics.filter(d => d.id !== id));
+    }
+  };
+
+  const handleUpdateDemographicName = (id: string, name: string) => {
+    setDemographics(demographics.map(d => d.id === id ? { ...d, name } : d));
+  };
+
+  const handleAddCategory = (demoId: string) => {
+    setDemographics(demographics.map(d =>
+      d.id === demoId
+        ? { ...d, categories: [...d.categories, `Category ${d.categories.length + 1}`] }
+        : d
+    ));
+  };
+
+  const handleRemoveCategory = (demoId: string, catIndex: number) => {
+    setDemographics(demographics.map(d => {
+      if (d.id === demoId && d.categories.length > 1) {
+        const newCats = [...d.categories];
+        newCats.splice(catIndex, 1);
+        return { ...d, categories: newCats };
+      }
+      return d;
+    }));
+  };
+
+  const handleUpdateCategory = (demoId: string, catIndex: number, value: string) => {
+    setDemographics(demographics.map(d => {
+      if (d.id === demoId) {
+        const newCats = [...d.categories];
+        newCats[catIndex] = value;
+        return { ...d, categories: newCats };
+      }
+      return d;
+    }));
+  };
+
+  // Trait management handlers
+  const handleAddTrait = () => {
+    setTraits([...traits, { id: generateId(), name: `Trait ${traits.length + 1}`, mean: 50, std: 15 }]);
+  };
+
+  const handleRemoveTrait = (id: string) => {
+    if (traits.length > 1) {
+      setTraits(traits.filter(t => t.id !== id));
+    }
+  };
+
+  const handleUpdateTrait = (id: string, field: keyof TraitConfig, value: string | number) => {
+    setTraits(traits.map(t => t.id === id ? { ...t, [field]: value } : t));
+  };
+
+  // Archetype probability handlers
+  const handleUpdateArchetypeProbability = (archId: string, prob: number) => {
+    setArchetypes(archetypes.map(a => a.id === archId ? { ...a, probability: prob } : a));
+  };
+
+  const handleNormalizeProbabilities = () => {
+    const total = archetypes.reduce((sum, a) => sum + a.probability, 0) || 1;
+    setArchetypes(archetypes.map(a => ({ ...a, probability: a.probability / total })));
+  };
+
+  if (!isOpen) return null;
+
   return (
     <div className="fixed inset-0 z-50 flex items-center justify-center bg-slate-900/50 backdrop-blur-sm">
       <div className="bg-white rounded-xl shadow-2xl w-full max-w-4xl overflow-hidden flex flex-col max-h-[90vh]">
@@ -303,7 +509,7 @@ export const SimulationWizard: React.FC = () => {
                 >
                   {llmProviders.length === 0 && (
                     <option value="">
-                      å°šæœªé…ç½®ä»»ä½•æä¾›å•†ï¼ˆè¯·å…ˆåœ¨â€œè®¾ç½®â€ä¸­æ·»åŠ ï¼‰
+                      å°šæœªé…ç½®ä»»ä½•æä¾›å•†ï¼ˆè¯·å…ˆåœ¨"è®¾ç½®"ä¸­æ·»åŠ ï¼‰
                     </option>
                   )}
                   {llmProviders.map((p) => (
@@ -316,7 +522,7 @@ export const SimulationWizard: React.FC = () => {
                 </select>
               </div>
 
-              {/* Template Selection #20 */}
+              {/* Template Selection */}
               <div>
                 <label className="block text-sm font-semibold text-slate-700 mb-3 flex items-center gap-2">
                   <LayoutTemplate size={16} /> 1. é€‰æ‹©åœºæ™¯æ¨¡æ¿
@@ -405,7 +611,7 @@ export const SimulationWizard: React.FC = () => {
                 />
               </div>
 
-              {/* Time Configuration #9 */}
+              {/* Time Configuration */}
               <div className="bg-indigo-50 border border-indigo-100 rounded-lg p-5">
                 <label className="block text-sm font-bold text-indigo-900 mb-3 flex items-center gap-2">
                   <Clock size={16} /> 3. ä»¿çœŸæ—¶é—´è®¾ç½® (Time Scale)
@@ -503,7 +709,7 @@ export const SimulationWizard: React.FC = () => {
                 >
                   {llmProviders.length === 0 && (
                     <option value="">
-                      å°šæœªé…ç½®ä»»ä½•æä¾›å•†ï¼ˆè¯·å…ˆåœ¨â€œè®¾ç½®â€ä¸­æ·»åŠ ï¼‰
+                      å°šæœªé…ç½®ä»»ä½•æä¾›å•†ï¼ˆè¯·å…ˆåœ¨"è®¾ç½®"ä¸­æ·»åŠ ï¼‰
                     </option>
                   )}
                   {llmProviders.map((p) => (
@@ -584,112 +790,239 @@ export const SimulationWizard: React.FC = () => {
               {/* MODE: AI GENERATE */}
               {importMode === 'generate' && (
                 <div className="flex-1 flex flex-col gap-4">
-                  <div className="grid grid-cols-1 md:grid-cols-4 gap-4 bg-purple-50 border border-purple-100 p-4 rounded-lg">
-                    <div className="col-span-1">
-                      <label className="block text-xs font-bold text-purple-800 mb-2">
-                        ç”Ÿæˆæ•°é‡
-                      </label>
-                      <input
-                        type="number"
-                        min="1"
-                        max="50"
-                        value={genCount}
-                        onChange={(e) =>
-                          setGenCount(
-                            Math.min(
-                              50,
-                              Math.max(1, parseInt(e.target.value))
-                            )
-                          )
-                        }
-                        className="w-full px-3 py-2 border border-purple-200 rounded text-sm focus:ring-purple-500"
-                      />
-                    </div>
-                    <div className="col-span-3">
-                      <label className="block text-xs font-bold text-purple-800 mb-2">
-                        ç¾¤ä½“ç”»åƒæè¿° (Population Distribution)
-                      </label>
-                      <textarea
-                        value={genDesc}
-                        onChange={(e) => setGenDesc(e.target.value)}
-                        className="w-full px-3 py-2 border border-purple-200 rounded text-sm focus:ring-purple-500 h-20 resize-none"
-                        placeholder="æè¿°ç¾¤ä½“çš„æ„æˆï¼Œä¾‹å¦‚ï¼š'ä¸€ä¸ªåŒ…æ‹¬5åå±…æ°‘çš„å°é•‡ï¼Œå…¶ä¸­2åæ˜¯ä¿å®ˆæ´¾å†œæ°‘ï¼Œ2åæ˜¯å¹´è½»æ¿€è¿›çš„å­¦ç”Ÿï¼Œ1åæ˜¯ä¸­ç«‹çš„æ•™å¸ˆã€‚'"
-                      />
-                    </div>
-                    <div className="col-span-4 flex justify-end">
-                      <button
-                        onClick={handleGenerateAgents}
-                        disabled={isGenerating}
-                        className="px-6 py-2 bg-purple-600 text-white text-sm font-bold rounded-lg hover:bg-purple-700 flex items-center gap-2 disabled:opacity-50"
-                      >
-                        {isGenerating ? (
-                          <Loader2
-                            size={16}
-                            className="animate-spin"
+                  {/* Demographics Toggle */}
+                  <div className="flex items-center gap-3 p-3 bg-purple-50 border border-purple-100 rounded-lg">
+                    <input
+                      type="checkbox"
+                      id="useDemographics"
+                      checked={useDemographics}
+                      onChange={(e) => setUseDemographics(e.target.checked)}
+                      className="w-4 h-4 text-purple-600 rounded"
+                    />
+                    <label htmlFor="useDemographics" className="flex-1">
+                      <span className="text-sm font-bold text-slate-800">Use Demographic Generation</span>
+                      <p className="text-xs text-slate-600">Define demographics and archetypes for large-scale generation</p>
+                    </label>
+                  </div>
+
+                  {/* Generation Count */}
+                  <div className="bg-purple-50 border border-purple-100 p-4 rounded-lg">
+                    <div className="flex items-center gap-4">
+                      <div className="w-32">
+                        <label className="block text-xs font-bold text-slate-700 mb-2">Agent Count</label>
+                        <input
+                          type="number"
+                          min="1"
+                          max="200"
+                          value={genCount}
+                          onChange={(e) => setGenCount(Math.min(200, Math.max(1, parseInt(e.target.value) || 1)))}
+                          className="w-full px-3 py-2 border border-purple-200 rounded text-sm focus:ring-purple-500"
+                        />
+                      </div>
+
+                      {!useDemographics && (
+                        <div className="flex-1">
+                          <label className="block text-xs font-bold text-slate-700 mb-2">Population Description</label>
+                          <textarea
+                            value={genDesc}
+                            onChange={(e) => setGenDesc(e.target.value)}
+                            className="w-full px-3 py-2 border border-purple-200 rounded text-sm focus:ring-purple-500 h-20 resize-none"
+                            placeholder="Describe population: 'A small town with 5 residents: 2 conservative farmers, 2 activist students, 1 neutral teacher.'"
                           />
-                        ) : (
-                          <Sparkles size={16} />
-                        )}
-                        å¼€å§‹ç”Ÿæˆ
-                      </button>
+                        </div>
+                      )}
                     </div>
                   </div>
 
+                  {/* Demographics Configuration */}
+                  {useDemographics && (
+                    <div className="space-y-4 bg-white border rounded-lg p-4">
+                      {/* Traits */}
+                      <div>
+                        <div className="flex justify-between items-center mb-2">
+                          <h4 className="text-sm font-bold text-slate-800">Trait Configuration</h4>
+                          <button onClick={handleAddTrait} className="text-xs text-purple-600 hover:text-purple-700 flex items-center gap-1 font-medium">
+                            <Plus size={12} /> Add Trait
+                          </button>
+                        </div>
+                        <div className="space-y-2">
+                          {traits.map((trait) => (
+  <div key={trait.id} className="flex items-center gap-2">
+    <input
+      value={trait.name}
+      onChange={(e) => handleUpdateTrait(trait.id, 'name', e.target.value)}
+      className="flex-1 px-2 py-1.5 text-sm border rounded text-slate-800"
+      placeholder="Trait name"
+    />
+    <span className="text-xs text-slate-500">Î¼</span>
+    <input
+      type="number"
+      value={trait.mean}
+      onChange={(e) => handleUpdateTrait(trait.id, 'mean', parseInt(e.target.value) || 50)}
+      className="w-16 px-2 py-1.5 text-sm border rounded text-center text-slate-800"
+      title="Mean"
+    />
+    <span className="text-xs text-slate-500">Ïƒ</span>
+    <input
+      type="number"
+      value={trait.std}
+      onChange={(e) => handleUpdateTrait(trait.id, 'std', parseInt(e.target.value) || 15)}
+      className="w-16 px-2 py-1.5 text-sm border rounded text-center text-slate-800"
+      title="Standard Deviation"
+    />
+    {traits.length > 1 && (
+      <button onClick={() => handleRemoveTrait(trait.id)} className="p-1 text-red-400 hover:text-red-600">
+        <X size={14} />
+      </button>
+    )}
+  </div>
+))}
+                        </div>
+                      </div>
+
+                      {/* Demographics */}
+                      <div>
+                        <div className="flex justify-between items-center mb-2">
+                          <h4 className="text-sm font-bold text-slate-800">Demographics</h4>
+                          <button onClick={handleAddDemographic} className="text-xs text-purple-600 hover:text-purple-700 flex items-center gap-1 font-medium">
+                            <Plus size={12} /> Add Dimension
+                          </button>
+                        </div>
+                        <div className="space-y-3">
+                          {demographics.map((demo) => (
+                            <div key={demo.id} className="bg-slate-50 rounded p-3">
+                              <div className="flex items-center gap-2 mb-2">
+                                <input
+                                  value={demo.name}
+                                  onChange={(e) => handleUpdateDemographicName(demo.id, e.target.value)}
+                                  className="flex-1 px-2 py-1.5 text-sm border rounded font-medium text-slate-800"
+                                  placeholder="Dimension name"
+                                />
+                                {demographics.length > 1 && (
+                                  <button onClick={() => handleRemoveDemographic(demo.id)} className="p-1 text-red-400 hover:text-red-600">
+                                    <Trash2 size={14} />
+                                  </button>
+                                )}
+                              </div>
+                              <div className="flex flex-wrap gap-2">
+                                {demo.categories.map((cat, catIdx) => (
+                                  <div key={catIdx} className="flex items-center bg-white rounded border">
+                                    <input
+                                      value={cat}
+                                      onChange={(e) => handleUpdateCategory(demo.id, catIdx, e.target.value)}
+                                      className="w-24 px-2 py-1.5 text-sm rounded-l border-0 text-slate-800"
+                                    />
+                                    {demo.categories.length > 1 && (
+                                      <button onClick={() => handleRemoveCategory(demo.id, catIdx)} className="px-1.5 text-red-400 hover:text-red-600">
+                                        <X size={12} />
+                                      </button>
+                                    )}
+                                  </div>
+                                ))}
+                                <button
+                                  onClick={() => handleAddCategory(demo.id)}
+                                  className="px-2 py-1.5 text-sm text-purple-600 hover:bg-purple-50 rounded border border-dashed border-purple-300"
+                                >
+                                  <Plus size={12} />
+                                </button>
+                              </div>
+                            </div>
+                          ))}
+                        </div>
+                      </div>
+
+                      {/* Archetypes Display */}
+                      {archetypes.length > 0 && (
+                        <div>
+                          <div className="flex justify-between items-center mb-2">
+                            <h4 className="text-sm font-bold text-slate-800">Archetypes ({archetypes.length})</h4>
+                            <button onClick={handleNormalizeProbabilities} className="text-xs text-purple-600 hover:text-purple-700 font-medium">
+                              Normalize
+                            </button>
+                          </div>
+                          <div className="max-h-[280px] overflow-y-auto space-y-2 border rounded p-2 bg-slate-50">
+                            {archetypes.map((arch) => (
+                              <div key={arch.id} className="bg-white p-3 rounded border">
+                                <div className="flex flex-wrap gap-2 mb-2">
+                                  {Object.entries(arch.attributes).map(([dimName, value]) => (
+                                    <span key={dimName} className="inline-flex items-center px-2 py-1 bg-indigo-100 text-indigo-800 text-xs rounded font-medium">
+                                      {dimName}: <span className="ml-1 font-bold">{value}</span>
+                                    </span>
+                                  ))}
+                                </div>
+
+                                <p className="text-xs text-slate-500 mb-2 italic">
+                                  Trait distributions (Î¼, Ïƒ) determined by LLM
+                                </p>
+
+                                <div className="flex items-center gap-2">
+                                  <span className="text-xs text-slate-600">Probability:</span>
+                                  <input
+                                    type="number"
+                                    min="0"
+                                    max="1"
+                                    step="0.01"
+                                    value={arch.probability.toFixed(2)}
+                                    onChange={(e) => handleUpdateArchetypeProbability(arch.id, Number(e.target.value))}
+                                    className="w-20 px-2 py-1 text-sm border rounded text-center text-slate-800"
+                                  />
+                                  <span className="text-xs text-slate-500">
+                                    (~{Math.max(1, Math.round(genCount * arch.probability))} agents)
+                                  </span>
+                                </div>
+                              </div>
+                            ))}
+                          </div>
+                        </div>
+                      )}
+                    </div>
+                  )}
+
+                  {/* Generate Button */}
+                  <button
+                    onClick={handleGenerateAgents}
+                    disabled={isGenerating || isGeneratingGlobal}
+                    className="w-full px-4 py-3 bg-purple-600 text-white rounded-lg font-medium hover:bg-purple-700 disabled:opacity-50 disabled:cursor-not-allowed flex items-center justify-center gap-2"
+                  >
+                    {isGenerating ? (
+                      <>
+                        <Loader2 className="animate-spin" size={16} />
+                        Generating...
+                      </>
+                    ) : (
+                      <>
+                        <Sparkles size={16} />
+                        {useDemographics ? `Generate ${genCount} Agents (Demographics)` : `Generate ${genCount} Agents (Description)`}
+                      </>
+                    )}
+                  </button>
+
+                  {/* Error Display */}
                   {importError && (
-                    <div className="p-3 bg-red-50 text-red-700 text-xs rounded border border-red-200">
+                    <div className="p-3 bg-red-50 border border-red-200 rounded text-sm text-red-600">
                       {importError}
                     </div>
                   )}
 
-                  {/* Preview for Generated Agents */}
+                  {/* Preview of Generated Agents */}
                   {customAgents.length > 0 && (
-                    <div className="flex-1 border rounded-lg overflow-hidden flex flex-col bg-white">
-                      <div className="px-4 py-2 bg-slate-50 border-b flex justify-between items-center">
-                        <span className="text-xs font-bold text-slate-700">
-                          å·²ç”Ÿæˆ {customAgents.length} ä¸ªæ™ºèƒ½ä½“
-                        </span>
-                        <button
-                          onClick={() => setCustomAgents([])}
-                          className="text-xs text-red-500 hover:underline"
-                        >
-                          æ¸…ç©ºé‡ç½®
-                        </button>
-                      </div>
-                      <div className="overflow-y-auto flex-1 p-0">
-                        <table className="w-full text-left text-xs">
-                          <thead className="bg-slate-50 sticky top-0 text-slate-500">
-                            <tr>
-                              <th className="px-4 py-2">å§“å</th>
-                              <th className="px-4 py-2">è§’è‰²</th>
-                              <th className="px-4 py-2">ç”»åƒæè¿°</th>
-                              <th className="px-4 py-2">åˆå§‹å±æ€§</th>
-                            </tr>
-                          </thead>
-                          <tbody className="divide-y">
-                            {customAgents.map((a, i) => (
-                              <tr
-                                key={i}
-                                className="hover:bg-slate-50"
-                              >
-                                <td className="px-4 py-2 font-bold">
-                                  {a.name}
-                                </td>
-                                <td className="px-4 py-2">
-                                  {a.role}
-                                </td>
-                                <td
-                                  className="px-4 py-2 max-w-xs truncate"
-                                  title={a.profile}
-                                >
-                                  {a.profile}
-                                </td>
-                                <td className="px-4 py-2 font-mono text-[10px] text-slate-500">
-                                  {JSON.stringify(a.properties)}
-                                </td>
-                              </tr>
-                            ))}
-                          </tbody>
-                        </table>
+                    <div className="border rounded-lg p-4 bg-green-50">
+                      <h4 className="text-sm font-bold text-slate-800 mb-2">
+                        Generated {customAgents.length} agents
+                      </h4>
+                      <div className="max-h-32 overflow-y-auto space-y-1">
+                        {customAgents.slice(0, 5).map((a) => (
+                          <div key={a.id} className="text-xs text-slate-600 flex items-center gap-2">
+                            <span className="font-medium">{a.name}</span>
+                            <span className="text-slate-400">Â·</span>
+                            <span>{a.role}</span>
+                          </div>
+                        ))}
+                        {customAgents.length > 5 && (
+                          <div className="text-xs text-slate-400 italic">
+                            ... {customAgents.length - 5} more
+                          </div>
+                        )}
                       </div>
                     </div>
                   )}
@@ -848,4 +1181,4 @@ export const SimulationWizard: React.FC = () => {
       </div>
     </div>
   );
-};
+};
\ No newline at end of file
diff --git a/frontend/store.ts b/frontend/store.ts
index ae4daa5..5edfe5c 100644
--- a/frontend/store.ts
+++ b/frontend/store.ts
@@ -964,6 +964,54 @@ export const generateAgentsWithAI = async (
   }));
 };
 
+// AgentTorch Integration: Demographic-based agent generation
+export async function generateAgentsWithDemographics(
+  totalAgents: number,
+  demographics: { name: string; categories: string[] }[],
+  archetypeProbabilities: Record<string, number>,
+  traits: { name: string; min: number; max: number }[],
+  language: string,
+  providerId?: string | number
+): Promise<Agent[]> {
+  const body = {
+    total_agents: totalAgents,
+    demographics,
+    archetype_probabilities: archetypeProbabilities,
+    traits,
+    language: language,
+    provider_id: providerId != null ? Number(providerId) : undefined
+  };
+
+  const res = await apiClient.post("/llm/generate_agents_demographics", body);
+  
+  const rawAgents: any[] = Array.isArray(res.data)
+    ? res.data
+    : Array.isArray(res.data?.agents)
+    ? res.data.agents
+    : [];
+
+  return rawAgents.map((a: any, index: number) => ({
+    id: a.id || `gen_${Date.now()}_${index}`,
+    name: a.name,
+    role: a.role || "è§’è‰²",
+    avatarUrl:
+      a.avatarUrl ||
+      `https://api.dicebear.com/7.x/avataaars/svg?seed=${encodeURIComponent(
+        a.name || `agent_${index}`
+      )}`,
+    profile: a.profile || "æš‚æ— æè¿°",
+    llmConfig: {
+      provider: a.provider || "backend",
+      model: a.model || "default"
+    },
+    properties: a.properties || {},
+    history: a.history || {},
+    memory: a.memory || [],
+    knowledgeBase: a.knowledgeBase || []
+  }));
+}
+
+
 
 // #12 Helper for Environment Suggestions
 export const fetchEnvironmentSuggestions = async (
@@ -2434,4 +2482,4 @@ export const useSimulationStore = create<AppState>((set, get) => ({
     }
     lastAuthState = nowAuth;
   });
-})();
+})();
\ No newline at end of file
diff --git a/src/socialsim4/backend/api/routes/llm.py b/src/socialsim4/backend/api/routes/llm.py
index 543cab0..3a01ec8 100644
--- a/src/socialsim4/backend/api/routes/llm.py
+++ b/src/socialsim4/backend/api/routes/llm.py
@@ -1,9 +1,10 @@
 # src/socialsim4/backend/api/routes/llm.py
 from __future__ import annotations
 
-from typing import Any, List, Optional
+from typing import Any, List, Optional, Dict
 import logging
 logger = logging.getLogger(__name__)
+
 from litestar import Router, post
 from litestar.connection import Request
 from pydantic import BaseModel, Field
@@ -14,18 +15,50 @@ from ...core.database import get_session
 from ...dependencies import extract_bearer_token, resolve_current_user
 from ...models.user import ProviderConfig
 
-# ğŸ‘‡ å…³é”®ï¼šè¿™é‡Œéœ€è¦ä¸Šå‡ 3 å±‚åˆ° socialsim4ï¼Œç„¶åå†è¿›å…¥ core
-from ....core.llm import create_llm_client
+# ğŸ”‘ Import from core.llm (4 levels up to socialsim4, then into core)
+from ....core.llm import (
+    create_llm_client,
+    generate_agents_with_archetypes,  # â† AgentTorch integration
+)
 from ....core.llm_config import LLMConfig
 
+
+# =============================================================================
+# Request/Response Models
+# =============================================================================
+
 class GenerateAgentsRequest(BaseModel):
+    """Request model for simple description-based agent generation."""
     count: int = Field(5, ge=1, le=50)
     description: str
-    # å‰ç«¯ generateAgentsWithAI é‡Œä¼ çš„ provider_id
+    provider_id: Optional[int] = None
+
+
+class DemographicDimension(BaseModel):
+    """A demographic dimension with categories (e.g., Age: [18-30, 31-50, 51+])."""
+    name: str
+    categories: List[str]
+
+
+class TraitConfig(BaseModel):
+    """Configuration for a trait with min/max bounds."""
+    name: str
+    mean: int = 50
+    std: int = 15
+
+
+class GenerateAgentsDemographicsRequest(BaseModel):
+    """Request model for demographic-based agent generation using AgentTorch."""
+    total_agents: int = Field(10, ge=1, le=200)
+    demographics: List[DemographicDimension]
+    archetype_probabilities: Dict[str, float] = {}
+    traits: List[TraitConfig] = []
+    language: str = "zh"  # Default to Chinese
     provider_id: Optional[int] = None
 
 
 class GeneratedAgent(BaseModel):
+    """Response model for a generated agent."""
     id: Optional[str] = None
     name: str
     role: Optional[str] = None
@@ -36,12 +69,22 @@ class GeneratedAgent(BaseModel):
     history: dict[str, Any] = {}
     memory: list[Any] = []
     knowledgeBase: list[Any] = []
+
+
+# =============================================================================
+# Helper Functions
+# =============================================================================
+
 async def _select_provider(
     session: AsyncSession,
     user_id: int,
     provider_id: Optional[int],
 ) -> ProviderConfig:
-    # ä¼˜å…ˆç”¨å‰ç«¯ä¼ å…¥çš„ provider_id
+    """
+    Select an LLM provider for the user.
+    Priority: provider_id from request > active provider > any provider
+    """
+    # Priority: use provider_id from frontend if specified
     if provider_id is not None:
         result = await session.execute(
             select(ProviderConfig).where(
@@ -53,7 +96,7 @@ async def _select_provider(
         if provider is None:
             raise RuntimeError("æŒ‡å®šçš„ LLM æä¾›å•†ä¸å­˜åœ¨æˆ–ä¸å±äºå½“å‰ç”¨æˆ·")
     else:
-        # å¦åˆ™æ‰¾ config.active çš„é‚£ä¸ªï¼›éƒ½æ²¡æ ‡ active å°±éšä¾¿æŒ‘ä¸€ä¸ª
+        # Otherwise find active provider or fallback to first available
         result = await session.execute(
             select(ProviderConfig).where(ProviderConfig.user_id == user_id)
         )
@@ -73,6 +116,12 @@ async def _select_provider(
         raise RuntimeError("LLM model required")
 
     return provider
+
+
+# =============================================================================
+# Endpoints
+# =============================================================================
+
 @post("/generate_agents")
 async def generate_agents(
     request: Request,
@@ -80,8 +129,9 @@ async def generate_agents(
 ) -> List[GeneratedAgent]:
     """
     POST /llm/generate_agents
-
-    å‰ç«¯çš„ generateAgentsWithAI() å°±æ˜¯è°ƒçš„è¿™ä¸ªæ¥å£ã€‚
+    
+    Simple description-based agent generation.
+    Frontend's generateAgentsWithAI() calls this endpoint.
     """
     token = extract_bearer_token(request)
 
@@ -105,24 +155,12 @@ async def generate_agents(
         )
         llm = create_llm_client(cfg)
 
-        system_prompt = (
-            "You are an agent generator for a social simulation platform. "
-            "Generate a list of diverse agents based on the user's scenario description. "
-            "IMPORTANT: Return ONLY a valid JSON array, no markdown, no explanation, no code blocks. "
-            "Each agent must have: name (string), role (string), profile (string), properties (object)."
-        )
+        system_prompt = "Generate agents for social simulation. Return ONLY valid JSON array."
 
         user_prompt = (
-            f"Generate exactly {data.count} diverse agents for this scenario:\n\n"
-            f"{data.description}\n\n"
-            "Requirements:\n"
-            "1. Each agent should have different identity, stance, and personality\n"
-            "2. Return ONLY a JSON array in this exact format:\n"
-            '[\n'
-            '  {"name": "Zhang San", "role": "Village Chief", "profile": "60-year-old respected leader...", "properties": {"trust": 70}},\n'
-            '  {"name": "Li Si", "role": "Merchant", "profile": "45-year-old shrewd businessman...", "properties": {"trust": 45}}\n'
-            ']\n\n'
-            "OUTPUT ONLY THE JSON ARRAY, NO OTHER TEXT:"
+            f"Generate {data.count} agents for: {data.description}\n\n"
+            "Return JSON: [{\"name\": str, \"role\": str, \"profile\": str, \"properties\": {}}]\n"
+            "NO markdown, NO text, ONLY JSON array:"
         )
 
         messages = [
@@ -131,26 +169,27 @@ async def generate_agents(
         ]
 
         raw_text = llm.chat(messages)
-   # æ‰“å°åŸå§‹è¾“å‡ºç”¨äºè°ƒè¯•
+        
+        # Print raw output for debugging
         logger.debug(f"LLM raw output (first 500 chars): {raw_text[:500]}")
         
         import json
         import re
         
-        # æ¸…ç† LLM è¾“å‡ºï¼šå»é™¤ markdown ä»£ç å—æ ‡è®°
+        # Clean LLM output: remove markdown code block markers
         cleaned_text = raw_text.strip()
 
-        # ç§»é™¤markdownä»£ç å—æ ‡è®°
+        # Remove markdown code block markers
         if cleaned_text.startswith("```"):
-            # åŒ¹é… ```json æˆ– ``` å¼€å¤´çš„ä»£ç å—
+            # Match ```json or ``` with content
             match = re.search(r'```(?:json)?\s*\n(.*?)\n```', cleaned_text, re.DOTALL)
             if match:
                 cleaned_text = match.group(1).strip()
             else:
-                # ç®€å•ç§»é™¤```æ ‡è®°
+                # Simple removal of ``` markers
                 cleaned_text = re.sub(r'^```(?:json)?|```$', '', cleaned_text, flags=re.MULTILINE).strip()
         
-        # å°è¯•æ‰¾åˆ°ç¬¬ä¸€ä¸ª[æˆ–{
+        # Try to find first [ or {
         json_start = min(
             (cleaned_text.find('[') if '[' in cleaned_text else len(cleaned_text)),
             (cleaned_text.find('{') if '{' in cleaned_text else len(cleaned_text))
@@ -163,39 +202,39 @@ async def generate_agents(
         except Exception as e:
             logger.error(f"JSON parse failed: {e}")
             logger.error(f"Cleaned text (first 300 chars): {cleaned_text[:300]}")
-            # LLM æ²¡æŒ‰è¦æ±‚è¿”å› JSON æ—¶çš„å…œåº•ï¼Œå‰ç«¯ä¾ç„¶èƒ½è·‘
-            parsed = [
-                {
-                    "name": f"Agent {i+1}",
-                    "role": "è§’è‰²",
-                    "profile": f"LLMè¿”å›æ ¼å¼é”™è¯¯ã€‚åŸå§‹è¾“å‡º: {raw_text[:100]}...",
-                    "properties": {},
-                }
-                for i in range(data.count)
-            ]
-
-        # å¤„ç†ä¸åŒçš„è¿”å›æ ¼å¼
+            raise RuntimeError(f"LLM returned invalid JSON: {e}")
+
+        # Validate response is a list
         if isinstance(parsed, dict) and "agents" in parsed:
             items = parsed["agents"]
         elif isinstance(parsed, list):
             items = parsed
         else:
-            # å¦‚æœè§£æå‡ºæ¥ä¸æ˜¯åˆ—è¡¨ä¹Ÿä¸æ˜¯åŒ…å« agents çš„å­—å…¸ï¼Œåˆ›å»ºå ä½è§’è‰²
-            items = []
+            raise RuntimeError("LLM response must be a JSON array")
 
         if not isinstance(items, list):
-            items = []
+            raise RuntimeError("LLM response must be a JSON array")
+
+        if len(items) != data.count:
+            raise RuntimeError(f"Expected {data.count} agents, got {len(items)}")
 
         agents: List[GeneratedAgent] = []
         for i, a in enumerate(items):
             if not isinstance(a, dict):
-                continue
+                raise RuntimeError(f"Agent {i} is not a valid object")
+            if not a.get("name"):
+                raise RuntimeError(f"Agent {i} missing required field: name")
+            if not a.get("role"):
+                raise RuntimeError(f"Agent {i} missing required field: role")
+            if not a.get("profile"):
+                raise RuntimeError(f"Agent {i} missing required field: profile")
+
             agents.append(
                 GeneratedAgent(
                     id=a.get("id") or None,
-                    name=a.get("name") or f"Agent {i+1}",
-                    role=a.get("role"),
-                    profile=a.get("profile"),
+                    name=a["name"],
+                    role=a["role"],
+                    profile=a["profile"],
                     provider=provider.provider or "backend",
                     model=provider.model or "default",
                     properties=a.get("properties") or {},
@@ -205,22 +244,103 @@ async def generate_agents(
                 )
             )
 
-        # å¦‚æœæ¨¡å‹è¿”å›çš„ä¸è¶³ count ä¸ªï¼Œç®€å•è¡¥é½
-        while len(agents) < data.count:
-            idx = len(agents)
+        return agents
+
+
+@post("/generate_agents_demographics")
+async def generate_agents_demographics(
+    request: Request,
+    data: GenerateAgentsDemographicsRequest,
+) -> List[GeneratedAgent]:
+    """
+    POST /llm/generate_agents_demographics
+    
+    Demographic-based agent generation using AgentTorch framework.
+    Frontend's generateAgentsWithDemographics() calls this endpoint.
+    
+    Process:
+    1. Generate archetypes from demographic cross-product
+    2. For each archetype, ONE LLM call to get description, roles, and trait distributions
+    3. Generate agents with Gaussian-sampled traits
+    4. Return agents with demographic properties
+    """
+    token = extract_bearer_token(request)
+
+    async with get_session() as session:
+        current_user = await resolve_current_user(session, token)
+
+        provider = await _select_provider(
+            session, current_user.id, data.provider_id
+        )
+
+        cfg = LLMConfig(
+            dialect=(provider.provider or "").lower(),
+            api_key=provider.api_key or "",
+            model=provider.model,
+            base_url=provider.base_url,
+            temperature=0.7,
+            top_p=1.0,
+            frequency_penalty=0.0,
+            presence_penalty=0.0,
+            max_tokens=1024,
+        )
+        llm = create_llm_client(cfg)
+
+        # Traits are required
+        if not data.traits:
+            raise RuntimeError("Traits are required for demographic generation")
+
+        # Convert Pydantic models to dicts for llm.py function
+        demographics_dicts = [
+            {"name": d.name, "categories": d.categories} 
+            for d in data.demographics
+        ]
+        
+        traits_dicts = [
+            {"name": t.name, "mean": t.mean, "std": t.std} 
+            for t in data.traits
+        ]
+
+        # ğŸ¯ Call the integrated AgentTorch function from llm.py
+        agents_data = generate_agents_with_archetypes(
+            total_agents=data.total_agents,
+            demographics=demographics_dicts,
+            archetype_probabilities=data.archetype_probabilities,
+            traits=traits_dicts,
+            llm_client=llm,
+            language=data.language
+        )
+
+        # Convert to GeneratedAgent response models
+        agents: List[GeneratedAgent] = []
+        for agent_dict in agents_data:
             agents.append(
                 GeneratedAgent(
-                    name=f"Agent {idx+1}",
-                    role="è§’è‰²",
-                    profile=data.description,
+                    id=agent_dict.get("id"),
+                    name=agent_dict.get("name", "Agent"),
+                    role=agent_dict.get("role"),
+                    profile=agent_dict.get("profile", ""),
                     provider=provider.provider or "backend",
                     model=provider.model or "default",
+                    properties=agent_dict.get("properties", {}),
+                    history=agent_dict.get("history", {}),
+                    memory=agent_dict.get("memory", []),
+                    knowledgeBase=agent_dict.get("knowledgeBase", []),
                 )
             )
 
+        logger.info(f"Generated {len(agents)} agents using demographic modeling")
         return agents
-# æš´éœ² /llm å‰ç¼€çš„ Router
+
+
+# =============================================================================
+# Router
+# =============================================================================
+
 router = Router(
     path="/llm",
-    route_handlers=[generate_agents],
-)
+    route_handlers=[
+        generate_agents,               # Simple generation
+        generate_agents_demographics,  # AgentTorch demographic generation
+    ],
+)
\ No newline at end of file
diff --git a/src/socialsim4/core/llm.py b/src/socialsim4/core/llm.py
index 8097af0..2626e89 100644
--- a/src/socialsim4/core/llm.py
+++ b/src/socialsim4/core/llm.py
@@ -1,10 +1,14 @@
 import os
 import re
 import time
+import random
+import math
+import json
 from concurrent.futures import ThreadPoolExecutor
 from concurrent.futures import TimeoutError as FutTimeout
 from threading import BoundedSemaphore
 from copy import deepcopy
+from typing import List, Dict, Any, Optional
 
 import google.generativeai as genai
 from openai import OpenAI
@@ -38,11 +42,11 @@ class LLMClient:
             max_concurrent = 1
         self._sem = BoundedSemaphore(max_concurrent)
 
-    # ----------- æ–°å¢ï¼šç”¨äºâ€œå¼ºéš”ç¦»æ¨¡å¼â€çš„ clone æ–¹æ³• -----------
+    # ----------- æ–°å¢ï¼šç”¨äº"å¼ºéš”ç¦»æ¨¡å¼"çš„ clone æ–¹æ³• -----------
     def clone(self) -> "LLMClient":
         """
-        ä¸º LLMClientPool çš„â€œå¼ºéš”ç¦»æ¨¡å¼â€æä¾›æ”¯æŒï¼šåˆ›å»ºä¸€ä¸ª
-        â€œåŠŸèƒ½ç­‰ä»·ä½†å®Œå…¨ç‹¬ç«‹â€çš„ LLMClient å®ä¾‹ã€‚
+        ä¸º LLMClientPool çš„"å¼ºéš”ç¦»æ¨¡å¼"æä¾›æ”¯æŒï¼šåˆ›å»ºä¸€ä¸ª
+        "åŠŸèƒ½ç­‰ä»·ä½†å®Œå…¨ç‹¬ç«‹"çš„ LLMClient å®ä¾‹ã€‚
 
         - provider ä½¿ç”¨ deepcopyï¼Œé¿å…åç»­ä¿®æ”¹äº’ç›¸å½±å“ï¼›
         - åº•å±‚ OpenAI/Gemini/Mock å®¢æˆ·ç«¯é‡æ–°åˆå§‹åŒ–ï¼ˆæ–°è¿æ¥ï¼‰ï¼›
@@ -52,7 +56,7 @@ class LLMClient:
         # 1. æ·±æ‹·è´ provider é…ç½®
         cloned_provider = deepcopy(self.provider)
 
-        # 2. æ„é€ ä¸€ä¸ªâ€œç©ºå£³â€å®ä¾‹ï¼ˆç»•è¿‡ __init__ï¼Œæ‰‹åŠ¨èµ‹å€¼ï¼‰
+        # 2. æ„é€ ä¸€ä¸ª"ç©ºå£³"å®ä¾‹ï¼ˆç»•è¿‡ __init__ï¼Œæ‰‹åŠ¨èµ‹å€¼ï¼‰
         cloned = LLMClient.__new__(LLMClient)
         cloned.provider = cloned_provider
 
@@ -256,52 +260,36 @@ def create_llm_client(provider: LLMConfig) -> LLMClient:
 
 
 class _MockModel:
-    """Deterministic local stub for offline testing.
-    Produces valid Thoughts/Plan/Action and optional Plan Update, with simple heuristics.
-    """
+    """Deterministic local stub for offline testing."""
 
     def __init__(self):
         self.agent_calls = {}
 
     def chat(self, messages):
-        # Extract system content (single string)
         sys_text = next((m["content"] for m in messages if m["role"] == "system"), "")
-
-        # Identify agent name
         m = re.search(r"You are\s+([^\n\.]+)", sys_text)
         agent_name = m.group(1).strip() if m else "Agent"
         self.agent_calls[agent_name] = self.agent_calls.get(agent_name, 0) + 1
         call_n = self.agent_calls[agent_name]
-
         sys_lower = sys_text.lower()
 
-        # Pick scene by keywords in system prompt
         if "grid-based virtual village" in sys_lower:
             scene = "map"
         elif "vote" in sys_lower or "voting" in sys_lower:
             scene = "council"
         elif "you are living in a virtual village" in sys_lower:
             scene = "village"
+        elif "werewolf" in sys_lower:
+            scene = "werewolf"
+        elif "dou dizhu" in sys_lower or "landlord" in sys_lower:
+            scene = "landlord"
         else:
-            # Detect scenes by keyword
-            if "werewolf" in sys_lower:
-                scene = "werewolf"
-            elif (
-                "dou dizhu" in sys_lower
-                or "landlord" in sys_lower
-                or "landlord_scene" in sys_lower
-            ):
-                scene = "landlord"
-            else:
-                scene = "chat"
+            scene = "chat"
 
         if scene == "council":
             if agent_name.lower() == "host":
                 if call_n == 1:
-                    action = {
-                        "action": "send_message",
-                        "message": "Good morning, council.",
-                    }
+                    action = {"action": "send_message", "message": "Good morning, council."}
                     thought = "Open the session briefly."
                     plan = "1. Greet. [CURRENT]"
                 else:
@@ -310,10 +298,7 @@ class _MockModel:
                     plan = "1. Yield. [CURRENT]"
             else:
                 if call_n == 1:
-                    action = {
-                        "action": "send_message",
-                        "message": "I support moving forward.",
-                    }
+                    action = {"action": "send_message", "message": "I support moving forward."}
                     thought = "Make a brief opening remark."
                     plan = "1. Remark. [CURRENT]"
                 else:
@@ -523,3 +508,230 @@ def action_to_xml(a):
         return f'<Action name="{name}" />'
     parts = "".join([f"<{k}>{a[k]}</{k}>" for k in params])
     return f'<Action name="{name}">{parts}</Action>'
+
+
+# =============================================================================
+# AgentTorch Integration: Archetype-Based Agent Generation
+# =============================================================================
+
+def generate_archetypes_from_demographics(demographics: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
+    """
+    Generate all archetype combinations from demographics.
+    
+    Args:
+        demographics: List of {"name": str, "categories": List[str]}
+    
+    Returns:
+        List of archetypes: [{"id", "attributes", "label", "probability"}, ...]
+    """
+    if not demographics:
+        return []
+    
+    # Start with first demographic
+    combinations = [{demographics[0]["name"]: cat} for cat in demographics[0]["categories"]]
+    
+    # Cross-product with remaining demographics
+    for demo in demographics[1:]:
+        new_combinations = []
+        for combo in combinations:
+            for cat in demo["categories"]:
+                new_combo = dict(combo)
+                new_combo[demo["name"]] = cat
+                new_combinations.append(new_combo)
+        combinations = new_combinations
+    
+    # Create archetype objects
+    equal_prob = 1.0 / len(combinations) if combinations else 0
+    archetypes = []
+    for i, attrs in enumerate(combinations):
+        label = " | ".join(f"{k}: {v}" for k, v in attrs.items())
+        archetypes.append({
+            "id": f"arch_{i}",
+            "attributes": attrs,
+            "label": label,
+            "probability": equal_prob
+        })
+    
+    return archetypes
+
+
+def add_gaussian_noise(value: float, std_dev: float, min_val: float = 0, max_val: float = 100) -> int:
+    """Add Gaussian noise to a value and clamp to min/max range."""
+    u1 = random.random() or 0.0001
+    u2 = random.random()
+    z = math.sqrt(-2 * math.log(u1)) * math.cos(2 * math.pi * u2)
+    noisy = value + z * std_dev
+    return int(round(max(min_val, min(max_val, noisy))))
+
+
+def generate_archetype_template(
+    archetype: Dict[str, Any], 
+    llm_client: LLMClient,
+    language: str = "en"
+) -> Dict[str, Any]:
+    """
+    Make ONE LLM call to get description and roles only.
+    Traits are now user-specified, not LLM-generated.
+    """
+    attrs_str = ", ".join(f"{k}: {v}" for k, v in archetype["attributes"].items())
+
+    if language == "zh":
+        prompt = f"""ä¸ºæ­¤äººå£åˆ›å»ºè§’è‰²æ¨¡æ¿: {attrs_str}
+
+è¿”å›è¿™ä¸ªæ ¼å¼çš„JSON:
+{{"description": "ä¸€å¥äººç‰©æè¿°", "roles": ["èŒä¸š1", "èŒä¸š2", "èŒä¸š3", "èŒä¸š4", "èŒä¸š5"]}}
+
+ä»…è¾“å‡ºJSONï¼Œæ— å…¶ä»–æ–‡å­—ã€‚"""
+    else:
+        prompt = f"""Create agent template for: {attrs_str}
+
+Return JSON in this exact format:
+{{"description": "one sentence bio", "roles": ["Job Title 1", "Job Title 2", "Job Title 3", "Job Title 4", "Job Title 5"]}}
+
+JSON only, no other text."""
+
+    messages = [
+        {"role": "system", "content": "Return only valid JSON."},
+        {"role": "user", "content": prompt}
+    ]
+    
+    response = llm_client.chat(messages)
+
+    # DEBUG
+    print(f"\n{'='*60}")
+    print(f"[DEBUG] Archetype: {attrs_str}")
+    print(f"[DEBUG] LLM Response: {response}")
+    print(f"{'='*60}\n")
+
+    # Strip markdown code blocks if present
+    cleaned = response.strip()
+    if cleaned.startswith("```"):
+        cleaned = re.sub(r'^```(?:json)?\s*', '', cleaned)
+        cleaned = re.sub(r'\s*```$', '', cleaned)
+
+    # Try to parse JSON from response
+    json_match = re.search(r'\{[\s\S]*\}', cleaned)
+    if not json_match:
+        raise RuntimeError(f"No JSON found in LLM response for archetype {attrs_str}")
+
+    parsed = json.loads(json_match.group())
+
+    # Validate required fields
+    if "description" not in parsed or not isinstance(parsed["description"], str):
+        raise RuntimeError(f"Missing or invalid 'description' for archetype {attrs_str}")
+    if "roles" not in parsed or not isinstance(parsed["roles"], list) or len(parsed["roles"]) == 0:
+        raise RuntimeError(f"Missing or invalid 'roles' for archetype {attrs_str}")
+
+    # Validate roles are strings
+    for i, r in enumerate(parsed["roles"]):
+        if not isinstance(r, str):
+            raise RuntimeError(f"Role {i} must be a string, got {type(r).__name__} for archetype {attrs_str}")
+
+    return {
+        "description": parsed["description"],
+        "roles": parsed["roles"]
+    }
+
+
+def generate_agents_with_archetypes(
+    total_agents: int,
+    demographics: List[Dict[str, Any]],
+    archetype_probabilities: Optional[Dict[str, float]],
+    traits: List[Dict[str, Any]],
+    llm_client: LLMClient,
+    language: str = "en"
+) -> List[Dict[str, Any]]:
+    """
+    Generate agents based on demographics and archetype probabilities.
+    Traits use user-specified mean/std directly.
+    """
+    # Validate inputs
+    if not traits:
+        raise ValueError("Traits are required for agent generation")
+    
+    # Validate trait format
+    for trait in traits:
+        if "mean" not in trait or "std" not in trait:
+            raise ValueError(f"Trait '{trait.get('name', 'unknown')}' must have 'mean' and 'std'")
+    
+    # Step 1: Generate archetypes
+    archetypes = generate_archetypes_from_demographics(demographics)
+    if not archetypes:
+        return []
+    
+    # Step 2: Apply custom probabilities
+    if archetype_probabilities:
+        for arch in archetypes:
+            if arch["id"] in archetype_probabilities:
+                arch["probability"] = archetype_probabilities[arch["id"]]
+    
+    # Step 3: Calculate agent counts per archetype
+    total_prob = sum(a["probability"] for a in archetypes) or 1.0
+    counts = {}
+    remaining = total_agents
+    
+    for i, arch in enumerate(archetypes):
+        if i == len(archetypes) - 1:
+            counts[arch["id"]] = remaining
+        else:
+            normalized_prob = arch["probability"] / total_prob
+            count = int(round(total_agents * normalized_prob))
+            count = min(count, remaining)
+            counts[arch["id"]] = count
+            remaining -= count
+    
+    # Step 4: Generate agents - ONE ARCHETYPE AT A TIME
+    agents = []
+    global_index = 0
+    
+    for arch in archetypes:
+        count = counts.get(arch["id"], 0)
+        if count == 0:
+            continue
+        
+        # ONE LLM call per archetype to get description and roles only
+        template = generate_archetype_template(arch, llm_client, language)
+        
+        # Create agents with random role and Gaussian noise on traits
+        for i in range(count):
+            agent_num = global_index + 1
+            name = f"Agent {agent_num}"
+            
+            # Randomly assign a role from LLM-generated list
+            role = random.choice(template["roles"]) if template["roles"] else "Citizen"
+            
+            # Generate trait values with Gaussian noise using USER-SPECIFIED mean/std
+            properties = {
+                "archetype_id": arch["id"],
+                "archetype_label": arch["label"],
+                **arch["attributes"]
+            }
+            
+            for trait in traits:
+                value = add_gaussian_noise(
+                    trait["mean"], 
+                    trait["std"],
+                    0,    # min clamp
+                    100   # max clamp (or make configurable)
+                )
+                properties[trait["name"]] = value
+            
+            # Profile is just the description
+            profile = template["description"]
+            
+            agent = {
+                "id": f"agent_{agent_num}",
+                "name": name,
+                "role": role,
+                "avatarUrl": f"https://api.dicebear.com/7.x/avataaars/svg?seed=agent{agent_num}",
+                "profile": profile,
+                "properties": properties,
+                "history": {},
+                "memory": [],
+                "knowledgeBase": []
+            }
+            
+            agents.append(agent)
+            global_index += 1
+    
+    return agents
diff --git a/validate_agents.py b/validate_agents.py
new file mode 100644
index 0000000..b6065eb
--- /dev/null
+++ b/validate_agents.py
@@ -0,0 +1,322 @@
+#!/usr/bin/env python3
+# Agent Generation Validation Script
+# ===================================
+# Location: Social-Sim/validate_agents.py
+#
+# Run from PowerShell:
+#   cd C:/Users/justi/Documents/ZJU_Work/Social-Sim
+#   $env:PYTHONPATH = "src"
+#   python validate_agents.py
+
+import json
+import math
+import sys
+import os
+
+# Add the src directory to path
+sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))
+
+print("=" * 60)
+print("  Agent Generation Validation Script")
+print("=" * 60)
+
+# ============================================================================
+# Step 1: Test Imports
+# ============================================================================
+print("\n[1/5] Testing imports...")
+
+try:
+    from socialsim4.core.llm import (
+        generate_archetypes_from_demographics,
+        add_gaussian_noise,
+        generate_archetype_template,
+        generate_agents_with_archetypes,
+    )
+    print("  OK - All imports successful")
+except ImportError as e:
+    print(f"  FAILED - Import failed: {e}")
+    print("\n  Make sure you're running from the Social-Sim directory")
+    sys.exit(1)
+
+
+# ============================================================================
+# Step 2: Test Gaussian Noise Statistics
+# ============================================================================
+print("\n[2/5] Testing Gaussian noise statistics...")
+
+# Test that mean and std are approximately correct
+test_mean = 50
+test_std = 15
+samples = [add_gaussian_noise(test_mean, test_std, 0, 100) for _ in range(5000)]
+
+actual_mean = sum(samples) / len(samples)
+variance = sum((x - actual_mean) ** 2 for x in samples) / len(samples)
+actual_std = math.sqrt(variance)
+
+print(f"  Expected: mean={test_mean}, std={test_std}")
+print(f"  Actual:   mean={actual_mean:.1f}, std={actual_std:.1f}")
+
+if abs(actual_mean - test_mean) < 3 and abs(actual_std - test_std) < 3:
+    print("  OK - Statistics are correct")
+else:
+    print("  FAILED - Statistics are off - check add_gaussian_noise function")
+
+# Test bounds
+out_of_bounds = [x for x in samples if x < 0 or x > 100]
+if len(out_of_bounds) == 0:
+    print("  OK - All values within bounds [0, 100]")
+else:
+    print(f"  FAILED - {len(out_of_bounds)} values out of bounds!")
+
+
+# ============================================================================
+# Step 3: Test Archetype Generation
+# ============================================================================
+print("\n[3/5] Testing archetype generation...")
+
+demographics = [
+    {"name": "Gender", "categories": ["Male", "Female"]},
+    {"name": "Education", "categories": ["High School", "Undergraduate", "Post-Graduate"]}
+]
+
+archetypes = generate_archetypes_from_demographics(demographics)
+
+expected_count = 2 * 3  # 2 genders x 3 education levels = 6
+if len(archetypes) == expected_count:
+    print(f"  OK - Generated {len(archetypes)} archetypes (expected {expected_count})")
+else:
+    print(f"  FAILED - Generated {len(archetypes)} archetypes, expected {expected_count}")
+
+# Check probabilities sum to 1
+total_prob = sum(a["probability"] for a in archetypes)
+if abs(total_prob - 1.0) < 0.001:
+    print(f"  OK - Probabilities sum to {total_prob:.4f}")
+else:
+    print(f"  FAILED - Probabilities sum to {total_prob}, expected 1.0")
+
+print("\n  Archetypes generated:")
+for a in archetypes:
+    print(f"    - {a['label']} (prob={a['probability']:.2f})")
+
+
+# ============================================================================
+# Step 4: Test LLM Response Parsing (with mock)
+# ============================================================================
+print("\n[4/5] Testing LLM response parsing...")
+
+class MockLLM:
+    def __init__(self, response):
+        self.response = response
+    def chat(self, messages):
+        return self.response
+
+archetype = {"attributes": {"Gender": "Male", "Education": "PhD"}}
+
+# Test 1: Valid JSON
+print("\n  Test 4a: Valid JSON parsing...")
+valid_response = json.dumps({
+    "description": "A test description for the agent",
+    "roles": ["Software Engineer", "Data Scientist", "Product Manager", "Designer", "Analyst"]
+})
+
+try:
+    result = generate_archetype_template(archetype, MockLLM(valid_response), "en")
+    if result["description"] == "A test description for the agent" and len(result["roles"]) == 5:
+        print("  OK - Valid JSON parsed correctly")
+    else:
+        print("  FAILED - Parsing gave unexpected result")
+except Exception as e:
+    print(f"  FAILED - Unexpected error: {e}")
+
+# Test 2: Markdown-wrapped JSON (common LLM behavior)
+print("\n  Test 4b: Markdown-wrapped JSON...")
+markdown_response = '```json\n{\n    "description": "Markdown wrapped response",\n    "roles": ["Role 1", "Role 2", "Role 3", "Role 4", "Role 5"]\n}\n```'
+
+try:
+    result = generate_archetype_template(archetype, MockLLM(markdown_response), "en")
+    if "Markdown" in result["description"]:
+        print("  OK - Markdown code blocks stripped correctly")
+    else:
+        print("  FAILED - Markdown stripping failed")
+except Exception as e:
+    print(f"  FAILED - Unexpected error: {e}")
+
+# Test 3: Missing description should fail
+print("\n  Test 4c: Missing 'description' rejected...")
+bad_response = json.dumps({"roles": ["A", "B", "C", "D", "E"]})
+
+try:
+    generate_archetype_template(archetype, MockLLM(bad_response), "en")
+    print("  FAILED - Should have raised an error!")
+except RuntimeError as e:
+    if "description" in str(e).lower():
+        print("  OK - Missing description correctly rejected")
+    else:
+        print(f"  FAILED - Wrong error message: {e}")
+
+# Test 4: Roles as objects should fail
+print("\n  Test 4d: Roles as objects rejected...")
+bad_response = json.dumps({
+    "description": "Test",
+    "roles": [{"title": "Manager"}, {"title": "Developer"}]
+})
+
+try:
+    generate_archetype_template(archetype, MockLLM(bad_response), "en")
+    print("  FAILED - Should have raised an error!")
+except RuntimeError as e:
+    if "string" in str(e).lower():
+        print("  OK - Roles as objects correctly rejected")
+    else:
+        print(f"  FAILED - Wrong error message: {e}")
+
+
+# ============================================================================
+# Step 5: Test Full Pipeline (with mock LLM)
+# ============================================================================
+print("\n[5/5] Testing full agent generation pipeline...")
+
+class MockLLMForPipeline:
+    def __init__(self):
+        self.call_count = 0
+    
+    def chat(self, messages):
+        self.call_count += 1
+        return json.dumps({
+            "description": f"Description for archetype {self.call_count}",
+            "roles": [
+                f"Role A{self.call_count}",
+                f"Role B{self.call_count}",
+                f"Role C{self.call_count}",
+                f"Role D{self.call_count}",
+                f"Role E{self.call_count}"
+            ]
+        })
+
+demographics = [
+    {"name": "Gender", "categories": ["Male", "Female"]},
+    {"name": "Education", "categories": ["HS", "UG"]}
+]
+traits = [
+    {"name": "IQ", "mean": 50, "std": 15},
+    {"name": "Creativity", "mean": 60, "std": 10}
+]
+
+mock_llm = MockLLMForPipeline()
+
+try:
+    agents = generate_agents_with_archetypes(
+        total_agents=20,
+        demographics=demographics,
+        archetype_probabilities=None,
+        traits=traits,
+        llm_client=mock_llm,
+        language="en"
+    )
+    
+    # Check count
+    if len(agents) == 20:
+        print(f"  OK - Generated {len(agents)} agents (expected 20)")
+    else:
+        print(f"  FAILED - Generated {len(agents)} agents, expected 20")
+    
+    # Check LLM calls (should be 4 = 2 genders x 2 education levels)
+    if mock_llm.call_count == 4:
+        print(f"  OK - Made {mock_llm.call_count} LLM calls (1 per archetype)")
+    else:
+        print(f"  FAILED - Made {mock_llm.call_count} LLM calls, expected 4")
+    
+    # Check agent structure
+    sample = agents[0]
+    required_fields = ["id", "name", "role", "profile", "properties"]
+    missing = [f for f in required_fields if f not in sample]
+    if not missing:
+        print("  OK - All required fields present")
+    else:
+        print(f"  FAILED - Missing fields: {missing}")
+    
+    # Check traits in properties
+    if "IQ" in sample["properties"] and "Creativity" in sample["properties"]:
+        print("  OK - Traits present in properties")
+    else:
+        print("  FAILED - Traits missing from properties")
+    
+    # Check trait statistics
+    iq_values = [a["properties"]["IQ"] for a in agents]
+    iq_mean = sum(iq_values) / len(iq_values)
+    print(f"  INFO - IQ mean = {iq_mean:.1f} (expected ~50)")
+    
+    # Show sample agent
+    print("\n  Sample agent:")
+    print(f"    ID: {sample['id']}")
+    print(f"    Name: {sample['name']}")
+    print(f"    Role: {sample['role']}")
+    print(f"    Profile: {sample['profile'][:50]}...")
+    print(f"    IQ: {sample['properties']['IQ']}")
+    print(f"    Creativity: {sample['properties']['Creativity']}")
+
+except Exception as e:
+    print(f"  FAILED - Pipeline failed: {e}")
+    import traceback
+    traceback.print_exc()
+
+
+# ============================================================================
+# Test Input Validation
+# ============================================================================
+print("\n[BONUS] Testing input validation...")
+
+# Test: Empty traits should fail
+print("\n  Test: Empty traits rejected...")
+try:
+    generate_agents_with_archetypes(
+        total_agents=10,
+        demographics=[{"name": "X", "categories": ["A"]}],
+        archetype_probabilities=None,
+        traits=[],  # Empty!
+        llm_client=MockLLMForPipeline(),
+        language="en"
+    )
+    print("  FAILED - Empty traits should raise an error!")
+except (ValueError, RuntimeError) as e:
+    print("  OK - Empty traits correctly rejected")
+
+# Test: Invalid trait format (min/max instead of mean/std)
+print("\n  Test: Invalid trait format rejected...")
+try:
+    generate_agents_with_archetypes(
+        total_agents=10,
+        demographics=[{"name": "X", "categories": ["A"]}],
+        archetype_probabilities=None,
+        traits=[{"name": "IQ", "min": 0, "max": 100}],  # Wrong format!
+        llm_client=MockLLMForPipeline(),
+        language="en"
+    )
+    print("  FAILED - Invalid trait format should raise an error!")
+except (ValueError, RuntimeError) as e:
+    print("  OK - Invalid trait format (min/max) correctly rejected")
+
+
+# ============================================================================
+# Summary
+# ============================================================================
+print("\n" + "=" * 60)
+print("  VALIDATION COMPLETE")
+print("=" * 60)
+print("")
+print("If all tests show OK, your code is ready for testing with real LLMs!")
+print("")
+print("Next steps:")
+print("1. Start your backend:")
+print("   cd src")
+print("   $env:PYTHONPATH = \".\"")
+print("   python -m uvicorn socialsim4.backend.main:app --host 0.0.0.0 --port 8000 --reload")
+print("")
+print("2. Start your frontend:")
+print("   cd frontend")
+print("   npm run dev")
+print("")
+print("3. Open http://localhost:5173/simulations/new")
+print("")
+print("4. Test with different LLM models (Qwen, Gemma, Ministral)")
+print("")
